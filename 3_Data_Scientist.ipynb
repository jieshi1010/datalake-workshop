{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3_Data_Scientist.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "PySpark",
      "language": "python",
      "name": "pyspark"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3TwAK_8Wll0"
      },
      "source": [
        "## 3. Data Scientist - Create ML models with Spark"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwCbd6SqWll0"
      },
      "source": [
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.classification import DecisionTreeClassifier, LogisticRegression\n",
        "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, f1_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7hujos_zCwi"
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder \\\n",
        ".appName('Spark - Data Scientist Demo') \\\n",
        ".config('spark.jars', 'gs://spark-lib/bigquery/spark-bigquery-latest.jar') \\\n",
        ".config(\"spark.jars.packages\", \"com.google.cloud.spark:spark-bigquery-with-dependencies_2.12:0.18.0\") \\\n",
        ".getOrCreate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZAK-gbxzCwj"
      },
      "source": [
        "spark.conf.get(\"spark.app.id\")\n",
        "spark.sparkContext._jvm.scala.util.Properties.versionString()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylnHDJ13zCwj"
      },
      "source": [
        "project_id = !gcloud config list --format 'value(core.project)' 2>/dev/null\n",
        "bq_raw_dataset_name = project_id[0] + '-raw'\n",
        "bq_raw_dataset_name = bq_raw_dataset_name.replace('-', '_')\n",
        "bq_raw_table_path = project_id[0] + ':' + bq_raw_dataset_name + '.transaction_data_train' \n",
        "bq_raw_table_path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asGBbiH5zCwk"
      },
      "source": [
        "#### Load Training Data using Spark"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p20yxBKHzCwl"
      },
      "source": [
        "data = spark.read \\\n",
        ".format(\"bigquery\") \\\n",
        ".option(\"table\", bq_raw_table_path) \\\n",
        ".load()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_y4K036kzCwn"
      },
      "source": [
        "data = data.drop('transactionID')\n",
        "data.cache()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGTkXZhtzCwn"
      },
      "source": [
        "#### Create a pyspark ML pipeline \n",
        "\n",
        "The pipeline will transform the features and train a Decision Tree classifier "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2kg4ewsvzCwo"
      },
      "source": [
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\n",
        "from pyspark.ml.classification import RandomForestClassifier, DecisionTreeClassifier\n",
        "\n",
        "\n",
        "categorical_cols = [field for (field, data_type) in data.dtypes \n",
        "                    if ((data_type == \"string\") & (field != 'isFraud'))]\n",
        "\n",
        "ohe_output_cols = [x + \"_OHE\" for x in categorical_cols]\n",
        "\n",
        "string_indexers = StringIndexer(inputCol='type', outputCol='type' +\"_Index\").fit(data) \n",
        "\n",
        "one_hot_indexer = OneHotEncoder(inputCol='type_Index', outputCol='type' +\"_OHE\")\n",
        "\n",
        "numeric_cols = [field for (field, data_type) in data.dtypes \n",
        "                if (((data_type == \"double\") | (data_type == \"int\") | (data_type == \"bigint\"))\n",
        "                  & (field != 'isFraud'))]\n",
        "\n",
        "assembler_inputs = ohe_output_cols + numeric_cols\n",
        "\n",
        "vec_assembler = VectorAssembler(\n",
        "    inputCols=assembler_inputs,\n",
        "    outputCol=\"features\")\n",
        "\n",
        "\n",
        "dtc = DecisionTreeClassifier(labelCol=\"isFraud\", featuresCol=\"features\", maxDepth=3, maxBins=12)\n",
        "\n",
        "\n",
        "pipeline = Pipeline(stages=[\n",
        "    string_indexers,\n",
        "    one_hot_indexer,\n",
        "    vec_assembler,\n",
        "    dtc \n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--lPFc7mzCwp"
      },
      "source": [
        "#### Train the model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGU9h1-rzCwq"
      },
      "source": [
        "model = pipeline.fit(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqH9COddzCwq"
      },
      "source": [
        "#### Persist the model to GCS "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnoutgo2zCwq"
      },
      "source": [
        "from pyspark.ml import Pipeline, PipelineModel\n",
        "\n",
        "gcs_bucket = project_id[0] + '-data'\n",
        "model_path = f'gs://{gcs_bucket}/model/'\n",
        "\n",
        "model.write().overwrite().save(model_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4MNqv4lzCwr"
      },
      "source": [
        "#### Predict on test data \n",
        "**TODO**\n",
        "* Provide path_to_predict_csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdasXGm7zCws"
      },
      "source": [
        "path_to_predict_csv = \"<gcs-path>/transaction_data_test.csv\"\n",
        "df_transaction_data_predict_from_csv = spark \\\n",
        ".read \\\n",
        ".option(\"inferSchema\" , \"true\") \\\n",
        ".option(\"header\" , \"true\") \\\n",
        ".csv(path_to_predict_csv)\n",
        "df_transaction_data_predict_from_csv.printSchema()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRp9QM2jzCws"
      },
      "source": [
        "Load the saved model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFjQsf5pzCws"
      },
      "source": [
        "loaded_pipeline_model = PipelineModel.load(model_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wd2X6ZbBzCwt"
      },
      "source": [
        "predictions = loaded_pipeline_model.transform(df_transaction_data_predict_from_csv)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BaR6_kfazCwt"
      },
      "source": [
        "predictions.show(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FFk6q7fzCwt"
      },
      "source": [
        "# Select example rows to display.\n",
        "predictions.select(\"prediction\", \"isFraud\").show(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBMiTQJqzCwu"
      },
      "source": [
        "### Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KYod7wWzCwu"
      },
      "source": [
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "\n",
        "binaryEvaluator = BinaryClassificationEvaluator(labelCol=\"isFraud\")\n",
        "\n",
        "auc = binaryEvaluator.evaluate(predictions, {binaryEvaluator.metricName: \"areaUnderROC\"})\n",
        "print(auc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXJV0AQgzCwu"
      },
      "source": [
        "tests_np = np.array((predictions.select(\"isFraud\",\"prediction\").collect()))\n",
        "tests_np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCbijvh6zCwv"
      },
      "source": [
        "tests_np = np.array((predictions.select(\"isFraud\",\"prediction\").collect()))\n",
        "\n",
        "np_acc = accuracy_score(tests_np[:,0], tests_np[:,1])\n",
        "np_f1 = f1_score(tests_np[:,0], tests_np[:,1])\n",
        "np_precision = precision_score(tests_np[:,0], tests_np[:,1])\n",
        "np_recall = recall_score(tests_np[:,0], tests_np[:,1])\n",
        "np_auc = roc_auc_score(tests_np[:,0], tests_np[:,1])\n",
        "\n",
        "print(\"f1:\", np_f1)\n",
        "print(\"precision:\", np_precision)\n",
        "print(\"recall:\", np_recall)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PlDr0C5DzCwv"
      },
      "source": [
        "#### Create confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0-_eqAszCwv"
      },
      "source": [
        "# import package that will generate the confusion matrix scores\n",
        "from sklearn.metrics import confusion_matrix\n",
        "# import packages that will help display the scores\n",
        "import pandas as pd\n",
        "\n",
        "confusion_matrix_scores = confusion_matrix(tests_np[:,0], \n",
        "                                           tests_np[:,1], \n",
        "                                           labels=[1, 0])\n",
        "\n",
        "# display scores as a heatmap\n",
        "df = pd.DataFrame(confusion_matrix_scores, \n",
        "                  columns = [\"Predicted True\", \"Predicted Not True\"],\n",
        "                  index = [\"Actually True\", \"Actually Not True\"])\n",
        "\n",
        "\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Q3YHVvezCww"
      },
      "source": [
        "bq_annotated_table_name = 'transaction_data_predictions'\n",
        "bq_annotated_table_path=  project_id[0] +  '_annotated.' + bq_annotated_table_name\n",
        "bq_annotated_table_path = bq_annotated_table_path.replace('-', '_')\n",
        "bq_annotated_table_path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDn4bdq1zCww"
      },
      "source": [
        "#### Persist predictions as an annotated dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwfUAozUzCwx"
      },
      "source": [
        "schema_inline = predictions.schema.simpleString().replace('struct<', '').replace('>', '').replace('int', 'int64').replace('double', 'float64').replace('bigint64', 'int64').replace('vector', 'STRING')\n",
        "\n",
        "!bq mk --table \\\n",
        "{bq_annotated_table_path} \\\n",
        "{schema_inline}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKDzZWhTzCwx"
      },
      "source": [
        "predictions.write \\\n",
        ".format(\"bigquery\") \\\n",
        ".option(\"table\", project_id[0]  + ':' + bq_annotated_table_path) \\\n",
        ".option(\"temporaryGcsBucket\", project_id[0]  + '-data') \\\n",
        ".mode('overwrite') \\\n",
        ".save()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6EreECmzCwy"
      },
      "source": [
        "annotated_dataset_name =  project_id[0] +  '_annotated'\n",
        "annotated_dataset_name = annotated_dataset_name.replace('-', '_')\n",
        "annotated_dataset_name"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGwxhnHGzCwy"
      },
      "source": [
        "**TODO** \n",
        "* Add annotated_dataset_name in the FROM clause below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-gJPCtxzCwz"
      },
      "source": [
        "%%bigquery\n",
        "SELECT * FROM <annotated_dataset_name>.INFORMATION_SCHEMA.TABLES;"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbZpvQ9nzCwz"
      },
      "source": [
        "#### Join buisness data to enrich the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k00qmMINzCwz"
      },
      "source": [
        "**TODO** \n",
        "* Provide the path to the join csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zf_shWXdzCw0"
      },
      "source": [
        "path_to_join_csv = \"gs://<enriched_dataset_name>/transaction_data_join.csv\"\n",
        "df_transaction_data_join_from_csv = spark \\\n",
        ".read \\\n",
        ".option(\"inferSchema\" , \"true\") \\\n",
        ".option(\"header\" , \"true\") \\\n",
        ".csv(path_to_join_csv)\n",
        "df_transaction_data_join_from_csv.printSchema()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjGflyBOzCw0"
      },
      "source": [
        "**TODO** (Challenge 2)\n",
        "* Join the 2 spark dataframes (predictions & df_transaction_data_join_from_csv) on transactionID field "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pm-AH24IzCw1"
      },
      "source": [
        "joined_result = predictions.join(df_transaction_data_join_from_csv, \"transactionID\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFE7tsZczCw1"
      },
      "source": [
        "joined_result.show(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2uQsRCbzCw2"
      },
      "source": [
        "joined_result.count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9K33zizTzCw2"
      },
      "source": [
        "#### Persist result as an enriched dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsiOiwSOzCw2"
      },
      "source": [
        "bq_enriched_table_name = 'transaction_analysis_enriched'\n",
        "bq_enriched_table_path = project_id[0] +  '_enriched.' + bq_enriched_table_name\n",
        "bq_enriched_table_path = bq_enriched_table_path.replace('-', '_')\n",
        "bq_enriched_table_path = project_id[0] + ':' + bq_enriched_table_path\n",
        "bq_enriched_table_path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zl_7sFOzCw2"
      },
      "source": [
        "schema_inline = joined_result.schema.simpleString().replace('struct<', '').replace('>', '').replace('int', 'int64').replace('bigint64', 'int64').replace('double', 'float64').replace('vector', 'STRING')\n",
        "\n",
        "!bq mk --table \\\n",
        "{bq_enriched_table_path} \\\n",
        "{schema_inline}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xG1fvtj6zCw3"
      },
      "source": [
        "joined_result.write \\\n",
        ".format(\"bigquery\") \\\n",
        ".option(\"table\", bq_enriched_table_path) \\\n",
        ".option(\"temporaryGcsBucket\", project_id[0]  + '-data') \\\n",
        ".mode('overwrite') \\\n",
        ".save()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dN-MyDCszCw3"
      },
      "source": [
        "enriched_dataset_name = project_id[0] +  '_enriched'\n",
        "enriched_dataset_name = enriched_dataset_name.replace('-', '_')\n",
        "enriched_dataset_name"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtXtLcrXzCw3"
      },
      "source": [
        "**TODO**\n",
        "* Provide the enriched_dataset_name in the FROM clause"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbiRVokHzCw4"
      },
      "source": [
        "%%bigquery\n",
        "SELECT * FROM <enriched_dataset_name>.INFORMATION_SCHEMA.TABLES;"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DvZz-RIczCw4"
      },
      "source": [
        "**TODO**\n",
        "* Query the enriched table"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbk3Woq0zCw4"
      },
      "source": [
        "%%bigquery \n",
        "<inser-code-here>\n",
        "LIMIT 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UY96LzmUzCw4"
      },
      "source": [
        "**TODO** (Optional: Challenge 3)\n",
        "* Improve the ML pipeline\n",
        "    * Try out different ML models [[doc]](https://spark.apache.org/docs/latest/ml-pipeline.html)\n",
        "    * Explore hyperparameter tuning \n",
        "    * How would you split the data when there is class imbalance? "
      ]
    }
  ]
}
